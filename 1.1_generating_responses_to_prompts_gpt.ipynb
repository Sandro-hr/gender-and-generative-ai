{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d285f285",
   "metadata": {},
   "source": [
    "## Import Libraries & Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62013c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8f6642-0ff7-448e-b186-d0794ce17d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column width to ensure that all characters are displayed\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7a2269-6db8-4372-b75e-720646338398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scripts and data path to the list of search paths\n",
    "script_dir = Path(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "sys.path.append(str(script_dir / \".\" / \"src\" / \"scripts\"))\n",
    "sys.path.append(str(script_dir / \".\" / \"data\" / \"products\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934177ad-cf73-4ab8-8b3c-d6eac616a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import code to automate querying of GPT\n",
    "from gpt import QueryGPT\n",
    "\n",
    "# import list of products\n",
    "from products import products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06fa3009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from the .env file\n",
    "# The .env file is where the \"OPEN_AI_API_KEY\" is stored\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c975f3a1-e313-4d31-8a47-35665223c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Open AI Key\n",
    "open_ai_api_key = os.environ['OPEN_AI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f6b61",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249211af-263b-4e42-9d5a-6e9f0b2abe1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beer',\n",
       " 'chocolate',\n",
       " 'ice cream',\n",
       " 'protein powder',\n",
       " 'a weight loss programme',\n",
       " 'a lawnmower',\n",
       " 'a car',\n",
       " 'a diy store',\n",
       " 'a supermarket',\n",
       " 'a clothes shop',\n",
       " 'furniture polish',\n",
       " 'a washing machine',\n",
       " 'dishwasher tablets',\n",
       " 'a vacuum cleaner',\n",
       " 'candles',\n",
       " 'bubble bath',\n",
       " 'curtains',\n",
       " 'electric drills',\n",
       " 'nappies',\n",
       " 'a science museum',\n",
       " 'an art gallery',\n",
       " 'a bookshop',\n",
       " 'a games console',\n",
       " 'a social network',\n",
       " 'a yoga class',\n",
       " 'a weightlifting class',\n",
       " 'a golf club',\n",
       " 'therapy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview list of products \n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23326c-0c77-4126-bd9f-f2ba73dead9e",
   "metadata": {},
   "source": [
    "## Generate Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606fc5f-81c0-45e7-bd96-4efa9390f77d",
   "metadata": {},
   "source": [
    "### GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24e7119-b8a3-4962-b095-3f21668faf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy model\n",
    "model = 'gpt-3.5-turbo'\n",
    "\n",
    "# initiate query object\n",
    "query_object = QueryGPT(open_ai_api_key=open_ai_api_key, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e87a5844-c773-4707-be07-c8126c2b77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list to store responses to the prompt\n",
    "responses = []\n",
    "\n",
    "# For each product, run prompt 40 times - generate a sufficiently large dataset\n",
    "for iteration in list(range(0,1)):\n",
    "    \n",
    "    for product in ['compost']:\n",
    "\n",
    "        # the search string specifies the prompt that is used\n",
    "        # query the Open AI API using hte prompt \"Write a script for an advert promoting X\"\n",
    "        search_string = f\"Write a script for an advert promoting {product}\"\n",
    "        \n",
    "        response = query_object.query_gpt(search_string = search_string)\n",
    "\n",
    "        # Append response to list\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e8dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the number of times the products list is replicated with the number \n",
    "products_multiplied = []\n",
    "\n",
    "for i in list(range(0,40)):\n",
    "    products_multiplied = products_multiplied+products\n",
    "\n",
    "# This code needs to be updated with a new file name to ensure that previous responses are not overwritten\n",
    "\n",
    "# Create a dictionary with all relevant parts of the response\n",
    "list_of_responses = []\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    \n",
    "    if isinstance(response, dict):\n",
    " \n",
    "        response_dict = {}\n",
    "        response_dict['unix_timestamp'] = response['created']\n",
    "        response_dict['id'] = response['id']\n",
    "        response_dict['prompt'] = f\"Write a script for an advert promoting {products_multiplied[i]}\"\n",
    "        response_dict['response'] = response['choices'][0]['message']['content']\n",
    "        response_dict['model'] = response['model']\n",
    "        response_dict['prompt_tokens'] = response['usage']['prompt_tokens']\n",
    "        response_dict['completion_tokens'] = response['usage']['completion_tokens']\n",
    "\n",
    "        list_of_responses.append(response_dict)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        continue\n",
    "\n",
    "# Convert dictionary to json\n",
    "response_json = json.dumps(list_of_responses)\n",
    "\n",
    "# Dump the json file \n",
    "# Update the file name so nothing is overwritten\n",
    "out_file = open(f\"\"\"data/raw_data/gpt3.5_responses_bulk_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.json\"\"\", \"w\")\n",
    "json.dump(response_json,out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f83e6-58ff-48a7-b612-de504fd00721",
   "metadata": {},
   "source": [
    "### GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b8eaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifiy model\n",
    "model = 'gpt-4'\n",
    "\n",
    "# initiate query object\n",
    "query_object = QueryGPT(open_ai_api_key=open_ai_api_key, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f095569c-b883-4ee9-a3c2-363f5fe2be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list to store responses to the prompt\n",
    "responses = []\n",
    "\n",
    "# For each product, run prompt 40 times - generate a sufficiently large dataset\n",
    "for iteration in list(range(0,1)):\n",
    "    \n",
    "    for product in ['socks']:\n",
    "\n",
    "        # the search string specifies the prompt that is used\n",
    "        # query the Open AI API using hte prompt \"Write a script for an advert promoting X\"\n",
    "        search_string = f\"Write a script for an advert promoting {product}\"\n",
    "        \n",
    "        response = query_object.query_gpt(search_string = search_string)\n",
    "\n",
    "        # Append response to list\n",
    "        responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d43a5b1-24c4-4de7-9047-3c61efd45700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the number of times the products list is replicated with the number \n",
    "products_multiplied = []\n",
    "\n",
    "for i in list(range(0,40)):\n",
    "    products_multiplied = products_multiplied+products\n",
    "\n",
    "# This code needs to be updated with a new file name to ensure that previous responses are not overwritten\n",
    "\n",
    "# Create a dictionary with all relevant parts of the response\n",
    "list_of_responses = []\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    \n",
    "    if isinstance(response, dict):\n",
    " \n",
    "        response_dict = {}\n",
    "        response_dict['unix_timestamp'] = response['created']\n",
    "        response_dict['id'] = response['id']\n",
    "        response_dict['prompt'] = f\"Write a script for an advert promoting {products_multiplied[i]}\"\n",
    "        response_dict['response'] = response['choices'][0]['message']['content']\n",
    "        response_dict['model'] = response['model']\n",
    "        response_dict['prompt_tokens'] = response['usage']['prompt_tokens']\n",
    "        response_dict['completion_tokens'] = response['usage']['completion_tokens']\n",
    "\n",
    "        list_of_responses.append(response_dict)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        continue\n",
    "\n",
    "# Convert dictionary to json\n",
    "response_json = json.dumps(list_of_responses)\n",
    "\n",
    "# Dump the json file \n",
    "# Update the file name so nothing is overwritten\n",
    "out_file = open(f\"\"\"data/raw_data/gpt4_responses_bulk_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.json\"\"\", \"w\")\n",
    "json.dump(response_json,out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2b994-1394-4b81-a653-2dc79eec1b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender_generative_ai",
   "language": "python",
   "name": "gender_generative_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
